{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1716208907320,"sparkVersion":"3.5.1","uid":"RegexTokenizer_15293fb3d484","paramMap":{"inputCol":"source_text","pattern":"\\W+","outputCol":"words"},"defaultParamMap":{"minTokenLength":1,"toLowercase":true,"pattern":"\\s+","gaps":true,"outputCol":"RegexTokenizer_15293fb3d484__output"}}
